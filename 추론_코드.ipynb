{"cells":[{"cell_type":"markdown","metadata":{"id":"dL1xvlSrdxYq"},"source":["# ChemBERT_MTR"]},{"cell_type":"markdown","metadata":{"id":"VzZpv9lWCUrk"},"source":["## 라이브러리(restart)"]},{"cell_type":"code","source":["# 런타임 재시작\n","!pip install -U \"numpy==1.26.4\""],"metadata":{"id":"gDuNOpA1ciuS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lp9pcyHEcqOz"},"source":["## 라이브러리2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SH7nhAAKckhm"},"outputs":[],"source":["# 드라이브 마운트 (colab에서만)\n","'''from google.colab import drive\n","drive.mount('/content/drive')'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CKzUTtPuuGi3"},"outputs":[],"source":["# (A) 우리 작업에 불필요하고 버전 충돌의 원인이 되는 패키지 제거\n","!pip uninstall -y bigframes peft diffusers gradio gcsfs cuml-cu12 umap-learn || true\n","\n","# (B) ChemBERTa에 필요한 핵심 스택만 확정 설치 (서로 호환되는 조합)\n","!pip install --no-cache-dir \\\n","  \"transformers==4.44.2\" \\\n","  \"tokenizers==0.19.1\" \\\n","  \"accelerate==0.34.2\" \\\n","  \"huggingface_hub==0.24.6\" \\\n","  \"datasets==2.20.0\" \\\n","  \"scikit-learn==1.6.1\" \\\n","  \"torchmetrics==1.4.0\" \\\n","  \"sentencepiece==0.1.99\"\n","\n","!pip install -U rdkit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F-JVMT2DfnxZ"},"outputs":[],"source":["# 라이브러리\n","import os, json, random, math, time\n","import numpy as np\n","import pandas as pd\n","from rdkit.Chem.Scaffolds.MurckoScaffold import MurckoScaffoldSmiles\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","import torch\n","from torch import nn\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n","    Trainer, TrainingArguments, set_seed\n",")\n","from rdkit import Chem\n","from transformers import EarlyStoppingCallback"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yn538kgCcpYK"},"outputs":[],"source":["# ===== 기본 설정 =====\n","SEED = 42\n","set_seed(SEED)\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","N_FOLDS = 5\n","OUTPUT_ROOT = \"./chemberta_5fold\"\n","\n","# ===== 스케줄러 & 얼리 스톱 설정 =====\n","LR_SCHEDULER = \"cosine_with_restarts\"\n","ES_PATIENCE = 5\n","ES_DELTA = 1e-4"]},{"cell_type":"markdown","metadata":{"id":"Yd_988xBgUl6"},"source":["## 추론"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h0isUuoXgLOp"},"outputs":[],"source":["# =========================\n","# infer_chemberta.py\n","# manifest.json을 읽어 각 fold의 best checkpoint로 TEST 예측 → 평균(소프트 앙상블) → 제출 저장\n","# 또한 어떤 체크포인트가 사용됐는지 출력\n","# =========================\n","\n","MANIFEST_PATH = os.path.join(OUTPUT_ROOT, \"manifest.json\")\n","\n","# ===== 유틸 =====\n","def canonicalize_smiles(smi: str):\n","    if pd.isna(smi):\n","        return None\n","    mol = Chem.MolFromSmiles(str(smi))\n","    return Chem.MolToSmiles(mol, canonical=True, isomericSmiles=True) if mol else None\n","\n","def pIC50_to_IC50(pIC50):\n","    return np.power(10.0, 9 - pIC50)\n","\n","# ===== 매니페스트 로드 =====\n","with open(MANIFEST_PATH, \"r\") as f:\n","    manifest = json.load(f)\n","\n","model_name = manifest[\"model_name\"]\n","max_len = int(manifest[\"max_len\"])\n","fold_entries = manifest[\"folds\"]\n","\n","test_csv_path = manifest.get(\"test_csv_path\", \"./test.csv\")\n","submission_name = manifest.get(\"submission_name\", \"submission_5fold.csv\")\n","\n","print(\"Loaded manifest:\", MANIFEST_PATH)\n","print(f\"model_name={model_name}, max_len={max_len}, n_folds={len(fold_entries)}\")\n","print(\"\\n=== Using checkpoints for ensembling ===\")\n","for f in fold_entries:\n","    print(f\"Fold {f['fold']}: epoch={f['best_epoch']}, score={float(f['best_score']):.6f}\")\n","    print(f\"           ckpt={f['checkpoint']}\")\n","\n","# ===== 토크나이저 =====\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# ===== 테스트 로드/전처리 =====\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Smiles'] = test_df['Smiles'].map(canonicalize_smiles)\n","\n","def tok_test_only(ex):\n","    return tokenizer(ex[\"Smiles\"], max_length=max_len, truncation=True, padding=\"max_length\")\n","\n","ds_test = Dataset.from_pandas(test_df[['Smiles']].copy())\n","ds_test = ds_test.map(tok_test_only)\n","ds_test.set_format(type='torch', columns=['input_ids','attention_mask'])\n","\n","# ===== 각 fold 체크포인트 로드하여 예측 =====\n","all_fold_preds = []\n","\n","for f in fold_entries:\n","    ckpt_dir = f[\"checkpoint\"]\n","    if not os.path.isdir(ckpt_dir):\n","        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_dir}\")\n","\n","    config = AutoConfig.from_pretrained(ckpt_dir)\n","    model  = AutoModelForSequenceClassification.from_pretrained(ckpt_dir, config=config)\n","\n","    # Trainer.predict를 재사용 (학습 없이 추론만)\n","    tmp_out = os.path.join(OUTPUT_ROOT, f\"infer_tmp_fold{f['fold']}\")\n","    args = TrainingArguments(\n","        output_dir=tmp_out,\n","        per_device_eval_batch_size=64,\n","        fp16=torch.cuda.is_available(),\n","        dataloader_num_workers=2,\n","        report_to=\"none\",\n","    )\n","    trainer = Trainer(model=model, args=args, tokenizer=tokenizer)\n","\n","    preds = trainer.predict(ds_test).predictions.reshape(-1)\n","    all_fold_preds.append(preds)\n","\n","# ===== 소프트 앙상블 & 제출 저장 =====\n","test_pic50_mean = np.mean(np.stack(all_fold_preds, axis=0), axis=0)\n","submission = pd.DataFrame({\n","    \"ID\": test_df[\"ID\"],\n","    \"ASK1_IC50_nM\": pIC50_to_IC50(test_pic50_mean)\n","})\n","\n","sub_path = os.path.join(OUTPUT_ROOT, submission_name)\n","submission.to_csv(sub_path, index=False)\n","print(\"\\nSaved submission:\", sub_path)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Lp9pcyHEcqOz"],"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOvf5UjlBdRxb7/fdyokHeg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}